{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynks1jlffxZe",
    "outputId": "10ce83f4-d401-461e-fcbc-a338fc23c48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 29 10:30:43 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:61:00.0 Off |                    0 |\n",
      "|  0%   59C    P0             87W /  300W |   40110MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    322657      C   /usr/bin/python                             38054MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this to clean GPU memory\n",
    "import torch\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset & configure templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_gux7ajYfxZf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18408\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"json\",name=\"SumeCzech\", data_files=\"./sumeczech/sumeczech-1.0-dev.jsonl\", split=\"train\", num_proc=32)\n",
    "dataset = load_dataset(\"json\",name=\"TranslatedInstruct\", data_files=\"./datasets/translated_dataset.jsonl\", split=\"train\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EctDCMg0fxZf"
   },
   "outputs": [],
   "source": [
    "# use only first 1000 examples\n",
    "# dataset = dataset.select(range(40000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EVTNvJG7fxZf"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch\n",
    "from accelerate import Accelerator\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z5Vj3tqXfxZg"
   },
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    \"\"\"\n",
    "    Prepare the input text for the model\n",
    "    \"\"\"\n",
    "    sys_val = example[\"conversations\"][0][\"value\"]\n",
    "    input_text = example[\"conversations\"][1][\"value\"]\n",
    "    response = example[\"conversations\"][2][\"value\"]\n",
    "#     in_text=\"###MISSING###\"\n",
    "#     out_text=\"###MISSING###\"\n",
    "    \n",
    "#     try:\n",
    "#         in_text = example['abstract']\n",
    "#         out_text = example['headline']\n",
    "#     except:\n",
    "# #         print(\"hehe something went wrong\")\n",
    "#         pass\n",
    "    return {\"text\": \n",
    "f\"\"\"### System:\n",
    "{sys_val}\n",
    "\n",
    "### Uživatel:\n",
    "{input_text}\n",
    "\n",
    "### Asistent:\n",
    "{response}\n",
    "<|endoftext|>[EOS]\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "krbEHZZ5qCKx"
   },
   "outputs": [],
   "source": [
    "# transform dataset so it has only field \"text\" with formatted prompts\n",
    "dataset = dataset.map(\n",
    "    formatting_prompts_func,\n",
    "    remove_columns=dataset.column_names,\n",
    "    num_proc=64,\n",
    "    batched=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVDEjeKTqFfg",
    "outputId": "ca33de5b-88c0-45a1-8e44-4adf54e766b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### System:\n",
      "Jsi asistentka AI. Poskytněte detailní odpověď, takže uživatel nemusí hledat venku, aby pochopil odpověď.\n",
      "\n",
      "### Uživatel:\n",
      "Informace: - Střední Asie nebo Střední Asie je hlavním regionem asijského kontinentu a táhne se od Kaspického moře na západě po Čínu na východě a od Afghánistánu na jihu po Rusko na severu. Je také hovorově označován jako \"stans\" (jako šest zemí, které jsou obecně považovány za v rámci regionu, mají všechny názvy končící perskou příponou \"-stan,\" což znamená \"země\") a je v rámci širšího euroasijského kontinentu.  - Kazachstán (dále jen \"Qazaqstan,\" \"Kazachstan\"), oficiálně Kazachstánská republika (\"Qazaqstan Respwblïkas\" \"Respublika Kazachstán\"), je transkontinentální zemí severní střední Asie a východní Evropy. Kazachstán je největší pevninou na světě, a devátá největší na světě, s oblastí. Kazachstán je ekonomicky dominantním národem střední Asie, který vytváří 60% HDP regionu, především prostřednictvím ropného/plynového průmyslu. Má také obrovské minerální zdroje.  - Kazachové (také hláskovaný Kazaks, Qazaqs,,; anglický název je transliterován z ruštiny) jsou Turci, kteří hlavně obývají jižní část východní Evropy Ural hory a severní části střední Asie (většinou Kazachstán, ale také nachází v částech Uzbekistánu, Číny, Ruska a Mongolska), region také známý jako euroasijský sub-kontinent. Kazašská identita je středověkého původu a byla silně utvářena základem kazašského chanátu mezi lety 1456 a 1465, kdy několik kmenů pod vládou sultánů Žanibek a Kerey odešli z Khanátu Abu'l-Khayr Khan.  - Dárek Stalinovi je 2008 kazašský film, který vypráví příběh malého chlapce jménem Sasha, který je poslán do Kazachstánu. Je zachráněn ze smrti starým kazašským mužem, Kasymem, který bere chlapce do jeho domu. Film se odehrává v roce 1949. Název, Dárek Stalinovi, má význam dvěma způsoby. První, v roce 1949, sovětská vláda provedla jaderný test na výročí Joseph Stalin's 70. narozeniny. Mnoho nevinných lidí se stalo obětí jaderného testu. Druhý význam se týká Sashova snu. Doufá, že pokud dá Stalin dar, bude moci vidět své rodiče znovu, aniž by věděl, že byli zabiti.    S jakým subjektem má \"dar na stagnování\" vztah \"původní jazyk práce\"?\n",
      "A:\n",
      "\n",
      "### Asistent:\n",
      "Subjekt \"Dárek Stalinovi\" má vztah \"původní jazyk práce\" s jazykem, ve kterém byl film původně vyroben, což je rusky. Kromě toho mohou existovat i některé kazašské dialogy, neboť příběh se odehrává v Kazachstánu.\n",
      "<|endoftext|>[EOS]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[69][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm9gHGlefxZg",
    "outputId": "764b8537-5e09-46f1-d8d3-8118af1219c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /storage/praha1/home/jurajdedic/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"BUT-FIT/CSTinyLlama-1.2B\"\n",
    "new_model_path = \"CSTinyLlama-1.2B-ft-SumeCzech\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\") # HF token TODO: zahodit do pice lebo public repo xd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & configure training \n",
    "- load model into the GPU\n",
    "- confogire LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "referenced_widgets": [
      "d3dd5ef4623e406daa5d2f019570f3b2",
      "8f26b29ee13c4f6e95e8cd723410718f",
      "d0f505d1cc81485989225fb328bc396a",
      "7486ae8153d444a6b57df2ca840490ee",
      "cb2a038fcda44e4da4d89e3767fa8911",
      "67f7b7125a4e42aabdd3614b3f8a079d",
      "046b7d5b13104068b60e0b67f7c8313d",
      "5ba881790f914e77ab171d906abc9d8d",
      "4bd047b485aa4e6d86cd4cda101cc98f",
      "8f8abfefc24942f4ad5fd62262b06168",
      "2ea80c14f1314b5c95fa997b67420dc9"
     ]
    },
    "id": "OiObI35wfxZg",
    "outputId": "21a673c1-c128-4dbb-ab07-4a7e35d85d30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, '[EOS]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.config.use_cache = False\n",
    "# model.config.pretraining_tp = 1\n",
    "\n",
    "import transformers\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    base_model_name, \n",
    "    trust_remote_code=True,\n",
    "#     padding=\"max_length\"\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# qlora for collab test\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# fix some fp16 issue\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.bos_token, tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'up_proj',\n",
       " 'o_proj',\n",
       " 'down_proj',\n",
       " 'gate_proj',\n",
       " 'k_proj',\n",
       " 'q_proj',\n",
       " 'v_proj']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Conv1D\n",
    "\n",
    "def get_specific_layer_names(model):\n",
    "    # Create a list to store the layer names\n",
    "    layer_names = []\n",
    "    \n",
    "    # Recursively visit all modules and submodules\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module is an instance of the specified layers\n",
    "        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.Conv2d, Conv1D)):\n",
    "            # model name parsing \n",
    "\n",
    "            layer_names.append('.'.join(name.split('.')[4:]).split('.')[0])\n",
    "    \n",
    "    return layer_names\n",
    "\n",
    "list(set(get_specific_layer_names(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(64002, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-21): 22 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=64002, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NHAZ2UW1fxZg"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=256, # TODO: Mozno zmenit\n",
    "    lora_dropout=0.1,\n",
    "    r=128, # TODO: Mozno zmenit\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"] #TODO: Mozno pridat aj dalsie\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class MemoryTrackerCallback(TrainerCallback):\n",
    "    def __init__(self, log_dir):\n",
    "        self.start_time = None\n",
    "        self.step_times = []\n",
    "        self.memory_usages = []\n",
    "        self.summary_writer = SummaryWriter(log_dir)  # Initialize SummaryWriter\n",
    "\n",
    "    def on_step_begin(self, args, state, control, **kwargs):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_step_end(self, args, state, control, model, **kwargs):\n",
    "        step_time = time.time() - self.start_time\n",
    "        self.step_times.append(step_time)\n",
    "\n",
    "        memory_usage = torch.cuda.max_memory_allocated() / (1024 ** 3)  # Convert to GB\n",
    "        self.memory_usages.append(memory_usage)\n",
    "\n",
    "        # Log step time and memory usage to TensorBoard\n",
    "        global_step = state.global_step\n",
    "        self.summary_writer.add_scalar(\"step_time\", step_time, global_step)\n",
    "        self.summary_writer.add_scalar(\"memory_usage\", memory_usage, global_step)\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        self.summary_writer.close()  # Close the SummaryWriter\n",
    "    \n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161,
     "referenced_widgets": [
      "6be2100c4c7f4605a4ed20d59627a830",
      "754e9f27204242f09fa7a3f59373512e",
      "71bf17a0908d48b4ad8e444ea014398f",
      "5d993c8164da4d42b1d1a00a171dd483",
      "fc0a449394a4422abb814f4f1e8d9319",
      "9745305d1cf6400e985450fcee4cca12",
      "d3bb4824364e485aa81859e4762df7a2",
      "7cfc37e675eb420590003bdd30eef482",
      "16a9c451d8424877ba84bd021334e9ee",
      "45c95b08e74845af90fe05f1ae826e14",
      "234bc12a982c41ae93b93156856c3a81"
     ]
    },
    "id": "umJcFMBPfxZh",
    "outputId": "2e18393e-a5f5-4591-eb4d-ed6c3ddc8ef5"
   },
   "outputs": [],
   "source": [
    "log_dir = \"./results\"\n",
    "memory_tracker = MemoryTrackerCallback(log_dir + \"/runs\")\n",
    "\n",
    "# Hyperparameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=log_dir,\n",
    "    num_train_epochs=4, # TODO: uvidime kolko bude stacit\n",
    "    per_device_train_batch_size=8, # TODO: mozno zmenit\n",
    "    gradient_accumulation_steps=2, # TODO: mozno zmenit\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=30,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "#     fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.06,\n",
    "    group_by_length=False, #could cause the oscillation in loss (https://github.com/artidoro/qlora/issues/228)\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= 2048, # maximum pre BUT Tiny LLama\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "#     callbacks=[memory_tracker],\n",
    "#     neftune_noise_alpha=5, #should improve the performance but needs to be tested\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "71iKvh-zfxZh",
    "outputId": "bfc19a89-3f80-4591-fed3-bb22c7bb7410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 100925440 || all params: 1332054016 || trainable%: 7.57667773136311\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4600' max='4600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4600/4600 2:41:41, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.432100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.274800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.316700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.232800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.196600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.160600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.177300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>2.138900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>2.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>2.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>2.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.160800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>2.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>2.070100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>2.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>2.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>2.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>2.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>2.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>2.067600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>2.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>2.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>2.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>2.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>2.073500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>2.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>2.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>2.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>2.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>2.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>2.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>2.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>2.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>2.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>2.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>2.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>2.115900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>2.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>1.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>2.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>2.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>1.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.932900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>1.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.897200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>1.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>1.868300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>1.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>1.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>1.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>1.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>1.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>2.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>1.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>1.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.969500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.959100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>1.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>1.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>1.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>1.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>1.979900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>1.882100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>1.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>1.914800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>1.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>1.952200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>1.919600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>1.957700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>1.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>1.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>1.995700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>1.913700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>1.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>1.808000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>1.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>1.885700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.892700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>1.833200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>1.840300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>1.822200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>1.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>1.823800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>1.820100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>1.815300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>1.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>1.885700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>1.885800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>1.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>1.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>1.831800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>1.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>1.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>1.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>1.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>1.856500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>1.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>1.819300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>1.918600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>1.841500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>1.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>1.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>1.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>1.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>1.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4530</td>\n",
       "      <td>1.869200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>1.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4590</td>\n",
       "      <td>1.822800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4600, training_loss=2.0363021203745966, metrics={'train_runtime': 9702.8581, 'train_samples_per_second': 7.589, 'train_steps_per_second': 0.474, 'total_flos': 3.1805350294880256e+17, 'train_loss': 2.0363021203745966, 'epoch': 3.9982616253802696})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_trainable_parameters(trainer.model)\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVYR0Gv0fxZh",
    "outputId": "d4525002-e110-45ef-a81e-57ee3dcd251f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CSTinyLlama-1.2B-ft-SumeCzech/tokenizer_config.json',\n",
       " 'CSTinyLlama-1.2B-ft-SumeCzech/special_tokens_map.json',\n",
       " 'CSTinyLlama-1.2B-ft-SumeCzech/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model_path)\n",
    "trainer.tokenizer.save_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgjgkYiCfxZh"
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "log_dir = \"./results/runs\"\n",
    "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for inference\n",
    "\n",
    "- build prompt\n",
    "- load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /storage/praha1/home/jurajdedic/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"BUT-FIT/CSTinyLlama-1.2B\"\n",
    "new_model_path = \"CSTinyLlama-1.2B-ft-InstructCS-r128-256\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\") # HF token TODO: zahodit do pice lebo public repo xd\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig.from_pretrained(new_model_path)\n",
    "new_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "new_tokenizer = AutoTokenizer.from_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VrYWMvktfxZi"
   },
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.CRITICAL)\n",
    "# pipe = pipeline(task=\"text-generation\", model=new_model, tokenizer=new_tokenizer, torch_dtype=torch.bfloat16, device_map=\"auto\", max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chat(input_text: str, sys_prompt: str=\"\"):\n",
    "    \n",
    "    return f\"\"\"### System:\n",
    "{sys_prompt}\n",
    "\n",
    "### Uživatel:\n",
    "{input_text}\n",
    "\n",
    "### Asistent:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_as_list(word_list):\n",
    "    \"Converts a sequence of words into a list of tokens\"\n",
    "    tokens_list = []\n",
    "    for word in word_list:\n",
    "        tokenized_word = new_tokenizer([word], add_special_tokens=False).input_ids[0]\n",
    "        tokens_list.append(tokenized_word)\n",
    "    return tokens_list\n",
    "\n",
    "\n",
    "bad_words_ids = get_tokens_as_list(word_list=[\"#\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### System:\n",
      "Jsi asistentka AI. Uživatel vám dá úkol. Vaším cílem je dokončit úkol tak věrně, jak můžete.\n",
      "\n",
      "### Uživatel:\n",
      "Jaké je hlavní město Francie?\n",
      "\n",
      "### Asistent:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = make_chat(\n",
    "    \"Jaké je hlavní město Francie?\",\n",
    "    \"Jsi asistentka AI. Uživatel vám dá úkol. Vaším cílem je dokončit úkol tak věrně, jak můžete.\"\n",
    ")\n",
    "example_encoded = new_tokenizer.encode(example, return_tensors=\"pt\",padding=True).to(torch.device(\"cuda\"))\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### System:\n",
      "Jsi asistentka AI. Uživatel vám dá úkol. Vaším cílem je dokončit úkol tak věrně, jak můžete.\n",
      "\n",
      "### Uživatel:\n",
      "Jaké je hlavní město Francie?\n",
      "\n",
      "### Asistent:\n",
      "Co se stane s vaším kolegou na konci hodiny v závislosti na výsledku úkolu?\n",
      "* Udělá to, co musí udělat *\n",
      "\n",
      "Jak dlouho bude trvat dokončení vašeho nového projektu do příštího týdne nebo měsíce závisí na tom kdy začnete pracovat a jaké máte výsledky z předchozích dnů. Když například pracujete celý týden jako konzultant pro svého klienta a dokončíte práci za méně než dva dny od začátku své směny (tj asi 6 hodin), budete mít čas 1 den navíc. Pokud jste předtím nepracovali vůbec žádný projekt, měli byste tento časový úsek vyplnit jinými úkoly - buď ve škole či doma, abyste získali více času k dokončení tohoto konkrétního problému. Čím rychleji jej vyřešíte tím lépe!\n",
      "V každém případě musíte být schopni dělat několik věcí zároveň; pokud si myslíte že by bylo dobré vyřešit jeden problém před dokončením dalšího jiného...\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    generation_output = new_model.generate(\n",
    "        input_ids=example_encoded,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "#         num_beams=5,\n",
    "        top_k=10,\n",
    "        top_p=0.99,\n",
    "        repetition_penalty=1.3,\n",
    "#         temperature=0.15,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=new_tokenizer.eos_token_id,\n",
    "    )\n",
    "# print(generation_output[0])\n",
    "op = new_tokenizer.decode(generation_output[0], skip_special_tokens=True)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvé trénovanie:\n",
    " -   alpha: 16, r: 8, batch_size: 4\n",
    " - výsledky: nanič\n",
    " - pri trénovaní sa loss postupne znižovala z 3.1 na 1.7, nasledoval spike na cca 2.8 potom loss postupne klesal \n",
    " - a toto sa opakovalo do konca (250 krokov, cca 4 takéto spiky)\n",
    " \n",
    "Ďalšie pokusy:\n",
    " - len ABSTRACT2HEADLINE\n",
    " - alpha: 16, r: 64, batch_size:8, group_by_length = False\n",
    " - opäť neúspech, menej oscilácie v loss\n",
    " \n",
    " - možno zaujímavé pozireť aj: https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/peft-flan-t5-int8-summarization.ipynb\n",
    "   - trénujú to cez Sequence2SequenceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer.decode(torch.tensor([2]), skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "046b7d5b13104068b60e0b67f7c8313d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16a9c451d8424877ba84bd021334e9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "234bc12a982c41ae93b93156856c3a81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ea80c14f1314b5c95fa997b67420dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45c95b08e74845af90fe05f1ae826e14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bd047b485aa4e6d86cd4cda101cc98f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ba881790f914e77ab171d906abc9d8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d993c8164da4d42b1d1a00a171dd483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45c95b08e74845af90fe05f1ae826e14",
      "placeholder": "​",
      "style": "IPY_MODEL_234bc12a982c41ae93b93156856c3a81",
      "value": " 10000/10000 [00:20&lt;00:00, 560.20 examples/s]"
     }
    },
    "67f7b7125a4e42aabdd3614b3f8a079d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be2100c4c7f4605a4ed20d59627a830": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_754e9f27204242f09fa7a3f59373512e",
       "IPY_MODEL_71bf17a0908d48b4ad8e444ea014398f",
       "IPY_MODEL_5d993c8164da4d42b1d1a00a171dd483"
      ],
      "layout": "IPY_MODEL_fc0a449394a4422abb814f4f1e8d9319"
     }
    },
    "71bf17a0908d48b4ad8e444ea014398f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cfc37e675eb420590003bdd30eef482",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16a9c451d8424877ba84bd021334e9ee",
      "value": 10000
     }
    },
    "7486ae8153d444a6b57df2ca840490ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f8abfefc24942f4ad5fd62262b06168",
      "placeholder": "​",
      "style": "IPY_MODEL_2ea80c14f1314b5c95fa997b67420dc9",
      "value": " 3/3 [01:08&lt;00:00, 22.76s/it]"
     }
    },
    "754e9f27204242f09fa7a3f59373512e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9745305d1cf6400e985450fcee4cca12",
      "placeholder": "​",
      "style": "IPY_MODEL_d3bb4824364e485aa81859e4762df7a2",
      "value": "Map: 100%"
     }
    },
    "7cfc37e675eb420590003bdd30eef482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f26b29ee13c4f6e95e8cd723410718f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67f7b7125a4e42aabdd3614b3f8a079d",
      "placeholder": "​",
      "style": "IPY_MODEL_046b7d5b13104068b60e0b67f7c8313d",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "8f8abfefc24942f4ad5fd62262b06168": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9745305d1cf6400e985450fcee4cca12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb2a038fcda44e4da4d89e3767fa8911": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0f505d1cc81485989225fb328bc396a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ba881790f914e77ab171d906abc9d8d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd047b485aa4e6d86cd4cda101cc98f",
      "value": 3
     }
    },
    "d3bb4824364e485aa81859e4762df7a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3dd5ef4623e406daa5d2f019570f3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f26b29ee13c4f6e95e8cd723410718f",
       "IPY_MODEL_d0f505d1cc81485989225fb328bc396a",
       "IPY_MODEL_7486ae8153d444a6b57df2ca840490ee"
      ],
      "layout": "IPY_MODEL_cb2a038fcda44e4da4d89e3767fa8911"
     }
    },
    "fc0a449394a4422abb814f4f1e8d9319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
